{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ab2b700-3eb9-498a-ba34-3e948a6e801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.\tDiabetes Risk Prediction using KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce22f913-d6f4-4057-a868-3bfc5b3465f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d10f724f-c2ab-40fc-bcf7-e43d3ba3e6cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'method' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiabetes.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m column_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPregnancies\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGlucose\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBloodPressure\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSkinThickness\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInsulin\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBMI\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDiabetesPedigreeFunction\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutcome\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m diabetes_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(df, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, names\u001b[38;5;241m=\u001b[39mcolumn_names) \n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m (data\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#check for missing values\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:719\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    716\u001b[0m errors \u001b[38;5;241m=\u001b[39m errors \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;66;03m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;00m\n\u001b[1;32m--> 719\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_binary_mode(path_or_buf, mode) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m    720\u001b[0m     mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    722\u001b[0m \u001b[38;5;66;03m# validate encoding and errors\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:1181\u001b[0m, in \u001b[0;36m_is_binary_mode\u001b[1;34m(handle, mode)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mtype\u001b[39m(handle), text_classes):\n\u001b[0;32m   1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, _get_binary_io_classes()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[0;32m   1182\u001b[0m     handle, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\n\u001b[0;32m   1183\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: argument of type 'method' is not iterable"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e866dd4b-ff1a-470f-9a8e-4cffd84c67ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e69d9595-a701-4dc1-a596-e5f9eefd8e83",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Excel file format cannot be determined, you must specify an engine manually.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Load the dataset from an Excel file\u001b[39;00m\n\u001b[0;32m     29\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiabetes.csv\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace with your Excel file path\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(file_path)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Assuming the last column is the label and the rest are features\u001b[39;00m\n\u001b[0;32m     33\u001b[0m X \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues  \u001b[38;5;66;03m# Features (all rows, all columns except the last)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m ExcelFile(\n\u001b[0;32m    496\u001b[0m         io,\n\u001b[0;32m    497\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    498\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m    499\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1554\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m inspect_excel_format(\n\u001b[0;32m   1551\u001b[0m         content_or_path\u001b[38;5;241m=\u001b[39mpath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options\n\u001b[0;32m   1552\u001b[0m     )\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1557\u001b[0m         )\n\u001b[0;32m   1559\u001b[0m engine \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_option(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mio.excel.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.reader\u001b[39m\u001b[38;5;124m\"\u001b[39m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: Excel file format cannot be determined, you must specify an engine manually."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "      \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e616946-f728-4026-bc88-4b7678d06bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1  \n",
      "Column names: Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
      "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
      "      dtype='object')\n",
      "Accuracy: 0.6818181818181818\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76        99\n",
      "           1       0.56      0.53      0.54        55\n",
      "\n",
      "    accuracy                           0.68       154\n",
      "   macro avg       0.65      0.65      0.65       154\n",
      "weighted avg       0.68      0.68      0.68       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "print(df.head())\n",
    "print(\"Column names:\", df.columns)\n",
    "\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "mean_pregnancies = X_train['Pregnancies'].mean()\n",
    "mean_glucose = X_train['Glucose'].mean()\n",
    "mean_bloodpressure = X_train['BloodPressure'].mean()\n",
    "mean_skinthickness = X_train['SkinThickness'].mean()\n",
    "mean_insulin = X_train['Insulin'].mean()\n",
    "mean_BMI = X_train['BMI'].mean()\n",
    "mean_diabetespedigreefunction = X_train['DiabetesPedigreeFunction'].mean()\n",
    "mean_age = X_train['Age'].mean()\n",
    "\n",
    "X_train['Pregnancies'] = X_train['Pregnancies'].fillna(mean_pregnancies)\n",
    "X_train['Glucose'] = X_train['Glucose'].fillna(mean_glucose)\n",
    "X_train['BloodPressure'] = X_train['BloodPressure'].fillna(mean_bloodpressure)\n",
    "X_train['SkinThickness'] = X_train['SkinThickness'].fillna(mean_skinthickness)\n",
    "X_train['Insulin'] = X_train['Insulin'].fillna(mean_insulin)\n",
    "X_train['BMI'] = X_train['BMI'].fillna(mean_BMI)\n",
    "X_train['DiabetesPedigreeFunction'] = X_train['DiabetesPedigreeFunction'].fillna(mean_diabetespedigreefunction)\n",
    "X_train['Age'] = X_train['Age'].fillna(mean_age)\n",
    "\n",
    "X_test['Pregnancies'] = X_test['Pregnancies'].fillna(mean_pregnancies)\n",
    "X_test['Glucose'] = X_test['Glucose'].fillna(mean_glucose)\n",
    "X_test['BloodPressure'] = X_test['BloodPressure'].fillna(mean_bloodpressure)\n",
    "X_test['SkinThickness'] = X_test['SkinThickness'].fillna(mean_skinthickness)\n",
    "X_test['Insulin'] = X_test['Insulin'].fillna(mean_insulin)\n",
    "X_test['BMI'] = X_test['BMI'].fillna(mean_BMI)\n",
    "X_test['DiabetesPedigreeFunction'] = X_test['DiabetesPedigreeFunction'].fillna(mean_diabetespedigreefunction)\n",
    "X_test['Age'] = X_test['Age'].fillna(mean_age)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7108015-290c-4515-ae72-3321de19bfea",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 41\u001b[0m\n\u001b[0;32m     37\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(feature_matrix, df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m], test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     39\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m---> 41\u001b[0m recommended_movies \u001b[38;5;241m=\u001b[39m predict(X_train, y_train, X_test, k)\n\u001b[0;32m     43\u001b[0m movie_title \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToy Story\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m movie_title \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues:\n",
      "Cell \u001b[1;32mIn[26], line 21\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(X_train, titles, X_test, k)\u001b[0m\n\u001b[0;32m     19\u001b[0m recommendations \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_point \u001b[38;5;129;01min\u001b[39;00m X_test:  \u001b[38;5;66;03m# Loop through all test points\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m     recommended_titles \u001b[38;5;241m=\u001b[39m predict_single(X_train, titles, test_point, k)  \u001b[38;5;66;03m# Predict for one test point\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     recommendations\u001b[38;5;241m.\u001b[39mappend(recommended_titles)  \u001b[38;5;66;03m# Store the recommendations\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m recommendations\n",
      "Cell \u001b[1;32mIn[26], line 10\u001b[0m, in \u001b[0;36mpredict_single\u001b[1;34m(X_train, y_train, test_point, k)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_single\u001b[39m(X_train, y_train, test_point, k):\n\u001b[1;32m---> 10\u001b[0m     distances \u001b[38;5;241m=\u001b[39m calculate_distances(X_train, test_point)  \u001b[38;5;66;03m# Get distances\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     sorted_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(distances)\n\u001b[0;32m     13\u001b[0m     k_nearest_titles \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[26], line 5\u001b[0m, in \u001b[0;36mcalculate_distances\u001b[1;34m(X_train, test_point)\u001b[0m\n\u001b[0;32m      3\u001b[0m distances \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_train \u001b[38;5;129;01min\u001b[39;00m X_train:\n\u001b[1;32m----> 5\u001b[0m     distance \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39msum((test_point \u001b[38;5;241m-\u001b[39m x_train) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m))  \u001b[38;5;66;03m# Euclidean distance\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     distances\u001b[38;5;241m.\u001b[39mappend(distance)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m distances\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "#Movie Recommendation System using KNN\n",
    "def calculate_distances(X_train, test_point):\n",
    "    distances = []\n",
    "    for x_train in X_train:\n",
    "        distance = np.sqrt(np.sum((test_point - x_train) ** 2))  # Euclidean distance\n",
    "        distances.append(distance)\n",
    "    return distances\n",
    "\n",
    "def predict_single(X_train, y_train, test_point, k):\n",
    "    distances = calculate_distances(X_train, test_point)  # Get distances\n",
    "    sorted_indices = np.argsort(distances)\n",
    "    \n",
    "    k_nearest_titles = []\n",
    "    for i in range(k):  # Collect the labels of the k nearest neighbors\n",
    "        k_nearest_titles.append(titles[sorted_indices[i]])\n",
    "    return k_nearest_titles\n",
    "\n",
    "def predict(X_train, titles, X_test, k):\n",
    "    recommendations = []\n",
    "    for test_point in X_test:  # Loop through all test points\n",
    "        recommended_titles = predict_single(X_train, titles, test_point, k)  # Predict for one test point\n",
    "        recommendations.append(recommended_titles)  # Store the recommendations\n",
    "    return recommendations    \n",
    "    \n",
    "df = pd.read_csv('movie_recommendation_system.csv')\n",
    "genre_dummies = df['genres'].str.get_dummies(sep=', ')\n",
    "df = pd.concat([df, genre_dummies], axis=1)\n",
    "\n",
    "features = df.drop(['movieId', 'title', 'genres', 'rating'], axis=1)\n",
    "ratings = df['rating'].values.reshape(-1, 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "ratings_scaled = scaler.fit_transform(ratings)\n",
    "\n",
    "feature_matrix = pd.concat([features, pd.DataFrame(ratings_scaled)], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_matrix, df['rating'], test_size=0.2, random_state=42)\n",
    "\n",
    "k = 5\n",
    "\n",
    "recommended_movies = predict(X_train, y_train, X_test, k)\n",
    "\n",
    "movie_title = \"Toy Story\" \n",
    "\n",
    "if movie_title in df['rating'].values:\n",
    "    movie_index = df[df['rating'] == movie_title].index[0]\n",
    "    test_point = feature_matrix.iloc[movie_index].values.reshape(1, -1)\n",
    "\n",
    "    recommended_movies = predict_single(X_train, y_train, test_point[0], k)\n",
    "    print(f\"\\nRecommended Movies for '{movie_title}':\")\n",
    "    for i, movie in enumerate(recommendations):\n",
    "        print(f\"{i + 1}: {movie}\")\n",
    "else:\n",
    "    print(f\"Movie '{movie_title}' not found in the dataset.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a5ac8f2-8b5a-435a-ac54-781fef9a1867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie 'Toy Story' not found in the dataset.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Function to calculate distances between a test point and all training points\n",
    "def calculate_distances(X_train, test_point):\n",
    "    distances = []\n",
    "    for x_train in X_train:\n",
    "        distance = np.sqrt(np.sum((test_point - x_train) ** 2))  # Euclidean distance\n",
    "        distances.append(distance)\n",
    "    return distances\n",
    "\n",
    "# Function to predict the titles of the k nearest movies\n",
    "def predict_single(X_train, titles, test_point, k):\n",
    "    distances = calculate_distances(X_train, test_point)  # Get distances\n",
    "    sorted_indices = np.argsort(distances)  # Get indices of neighbors sorted by distance\n",
    "    \n",
    "    k_nearest_titles = []\n",
    "    for i in range(k):  # Collect the titles of the k nearest neighbors\n",
    "        k_nearest_titles.append(titles.iloc[sorted_indices[i]])  # Use iloc to get the title\n",
    "    return k_nearest_titles\n",
    "\n",
    "# Function to predict titles for all test points\n",
    "def predict(X_train, titles, X_test, k):\n",
    "    recommendations = []\n",
    "    for test_point in X_test:  # Loop through all test points\n",
    "        recommended_titles = predict_single(X_train, titles, test_point, k)  # Predict for one test point\n",
    "        recommendations.append(recommended_titles)  # Store the recommendations\n",
    "    return recommendations    \n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('movie_recommendation_system.csv')\n",
    "\n",
    "# One-hot encode the Genre column\n",
    "genre_dummies = df['genres'].str.get_dummies(sep=', ')\n",
    "df = pd.concat([df, genre_dummies], axis=1)\n",
    "\n",
    "# Prepare the feature matrix\n",
    "features = df.drop(['movieId', 'title', 'genres', 'rating'], axis=1)\n",
    "ratings = df['rating'].values.reshape(-1, 1)\n",
    "\n",
    "# Normalize the ratings\n",
    "scaler = StandardScaler()\n",
    "ratings_scaled = scaler.fit_transform(ratings)\n",
    "\n",
    "# Combine features and normalized ratings\n",
    "feature_matrix = pd.concat([features, pd.DataFrame(ratings_scaled)], axis=1)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_matrix, df['title'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Set the value of k\n",
    "k = 5\n",
    "\n",
    "# Test the recommendation system with a specific movie input\n",
    "movie_title = \"Toy Story\" \n",
    "\n",
    "# Find the index of the movie \"Toy Story\"\n",
    "if movie_title in df['title'].values:\n",
    "    movie_index = df[df['title'] == movie_title].index[0]\n",
    "    test_point = feature_matrix.iloc[movie_index].values.reshape(1, -1)\n",
    "\n",
    "    # Get recommendations for the specified movie\n",
    "    recommended_movies = predict_single(X_train, y_train, test_point[0], k)\n",
    "    \n",
    "    # Print the recommendations\n",
    "    print(f\"\\nRecommended Movies for '{movie_title}':\")\n",
    "    for i, movie in enumerate(recommended_movies):\n",
    "        print(f\"{i + 1}: {movie}\")\n",
    "else:\n",
    "    print(f\"Movie '{movie_title}' not found in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df36abd8-4667-4c06-9c55-c0ecceb8382a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
